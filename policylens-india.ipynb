{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9938431,"sourceType":"datasetVersion","datasetId":6109762},{"sourceId":85984,"sourceType":"modelInstanceVersion","modelInstanceId":72244,"modelId":78150}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/yahayamkayode/fine-tuning-gemma2b-model-using-lora-and-keras?scriptVersionId=208046475\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"<center><h1>Fine-tuning Gemma 2 Model Using LoRA and Keras with Custom Datatset</h1></center>\n\n\n# Introduction\n\n> In this project, I developed PolicyLens-India, an advanced conversational AI chatbot capable of answering questions based on Indian parliamentary debates and policies. The model is fine-tuned using Gemma2_2b, leveraging a custom Q&A-style dataset created from Indian parliamentary debate documents spanning 2023–2024.\n\n> The dataset includes 1800 QA pairs derived from comprehensive debates covering legislative processes, policy discussions, and key national issues. The chatbot's performance was rigorously evaluated on 100 QA pairs generated from 2024 parliamentary debates, achieving over 90% accuracy.\n\n\n#### The following resources were acknowledged for the successful implementation of this project\n\n> 1. Fine-tune Gemma models in Keras using LoRA, Kaggle Code, https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora (Version 1) \n> 2. Fine-tune Gemma using LoRA and Keras, https://www.kaggle.com/code/gpreda/fine-tune-gemma-using-lora-and-keras\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# What is Gemma 2?\n\n> Gemma is a collection of lightweight, advanced open models developed by Google, leveraging the same research and technology behind the Gemini models. These models are text-to-text, decoder-only large language models available in English, with open weights provided for both pre-trained and instruction-tuned versions. Gemma models excel in a range of text generation tasks, such as question answering, summarization, and reasoning. Their compact size allows for deployment in resource-constrained environments like laptops, desktops, or personal cloud infrastructure, making state-of-the-art AI models more accessible and encouraging innovation for all. \n\n> Gemma 2 represent the 2nd generation of Gemma models. These models were trained on a dataset of text data that includes a wide variety of sources. The **27B** model was trained with **13 trillion** tokens, the **9B** model was trained with **8 trillion tokens**, and **2B** model was trained with **2 trillion** tokens. Here is a summary of their key components: \n\n> To learn more about Gemma 2, follow this link: [Gemma 2 Model Card](https://www.kaggle.com/models/google/gemma-2).\n","metadata":{}},{"cell_type":"markdown","source":"# What is LoRA?  \n\n> **LoRA** stands for **Low-Rank Adaptation**. It is a method used to fine-tune large language models (LLMs) by freezing the weights of the LLM and injecting trainable rank-decomposition matrices. The number of trainable parameters during fine-tunning will decrease therefore considerably. According to **LoRA** paper, this number decreases **10,000 times**, and the computational resources size decreases 3 times. ","metadata":{}},{"cell_type":"markdown","source":"# How we proceed?\n\n> For fine-tunning with LoRA, we will follow the steps:\n\n> 1. Install prerequisites\n> 2. Load and process the maize data for fine-tuning\n> 3. Initialize the code for Gemma causal language model (Gemma Causal LM)\n> 4. Perform fine-tuning\n> 5. Test the fine-tunned model with questions from the data used for fine-tuning and with aditional questions","metadata":{}},{"cell_type":"markdown","source":"# Prerequisites\n\n\n## Install packages\n\nWe start by installing `keras-nlp` and `keras` packages.","metadata":{}},{"cell_type":"code","source":"# Install dependencies\n!pip install -q -U wurlitzer\n!pip install keras-core\n!pip install -q -U keras-nlp\n!pip install -q -U keras==3.5.0  # Use Keras 3.x to work with JAX\n!pip install -q -U kagglehub --upgrade\n!pip install jax jaxlib\n!pip install keras-nlp\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T09:41:04.331098Z","iopub.execute_input":"2024-11-18T09:41:04.331507Z","iopub.status.idle":"2024-11-18T09:42:29.042285Z","shell.execute_reply.started":"2024-11-18T09:41:04.331469Z","shell.execute_reply":"2024-11-18T09:42:29.041314Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (0.1.7)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core) (3.11.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.1.8)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.2)\nRequirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (0.4.26)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (0.4.26.dev20240620)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax) (0.3.2)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from jax) (1.26.4)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax) (1.14.1)\nRequirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.17.0)\nRequirement already satisfied: keras-hub==0.17.0 in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.17.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (21.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (2024.5.15)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (13.7.1)\nRequirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (0.3.4)\nRequirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras-nlp) (2.16.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-hub==0.17.0->keras-nlp) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras-hub==0.17.0->keras-nlp) (4.66.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-hub==0.17.0->keras-nlp) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.17.0->keras-nlp) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.17.0->keras-nlp) (2.18.0)\nRequirement already satisfied: tensorflow<2.17,>=2.16.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras-hub==0.17.0->keras-nlp) (2.16.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.17.0->keras-nlp) (0.1.2)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.37.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras-nlp) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras-nlp) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras-nlp) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras-hub==0.17.0->keras-nlp) (2024.8.30)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.43.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.11.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-hub==0.17.0->keras-nlp) (2.1.5)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install keras-nlp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import packages\n\nNow we can import the packages we just installed. We will also install `os`, so that we can set the environment variables needed for keras backend. We will use `jax` as `KERAS_BACKEND`.\n\nBecause we want to publish the Model from the Notebook, we also include `kagglehub` and import secrets from `Kaggle App`.","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\nos.environ[\"JAX_PLATFORMS\"] = \"\"\nimport keras\nimport keras_nlp\nimport kagglehub\n\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"KAGGLE_KEY\")\nsecret_value_1 = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas() # progress bar for pandas\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, Markdown","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:29.044381Z","iopub.execute_input":"2024-11-18T09:42:29.044720Z","iopub.status.idle":"2024-11-18T09:42:42.010100Z","shell.execute_reply.started":"2024-11-18T09:42:29.044687Z","shell.execute_reply":"2024-11-18T09:42:42.009317Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Configurations\n\n\nWe use a `Config` class to group the information needed to control the fine-tuning process:\n* random seed \n* dataset path\n* preset - name of pretrained Gemma 2\n* sequence length - this is the maximum size of input sequence for training\n* batch size - size of the input batch in training, x 2 as two GPUs\n* lora rank - rank for LoRA, higher means more trainable parameters \n* learning rate used in the train\n* epochs - number of epochs for train","metadata":{}},{"cell_type":"code","source":"class Config:\n    seed = 42\n\n    dataset_path = \"/kaggle/input/indian-parliamentary-debates-data-2024\"  # Use your dataset's Kaggle path\n    preset = \"gemma2_2b_en\" # name of pretrained Gemma 2\n    sequence_length = 512 # max size of input sequence for training\n    batch_size = 1 # size of the input batch in training\n    lora_rank = 4 # rank for LoRA, higher means more trainable parameters\n    learning_rate=8e-5 # learning rate used in train\n    epochs = 12 # number of epochs to train\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:42.011269Z","iopub.execute_input":"2024-11-18T09:42:42.011756Z","iopub.status.idle":"2024-11-18T09:42:42.019744Z","shell.execute_reply.started":"2024-11-18T09:42:42.011722Z","shell.execute_reply":"2024-11-18T09:42:42.018997Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"keras.utils.set_random_seed(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:42.022116Z","iopub.execute_input":"2024-11-18T09:42:42.022983Z","iopub.status.idle":"2024-11-18T09:42:42.053316Z","shell.execute_reply.started":"2024-11-18T09:42:42.022934Z","shell.execute_reply":"2024-11-18T09:42:42.052422Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Load the data\n\n\nWe load the data we will use for fine-tunining.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(f\"{Config.dataset_path}/PolicyData_2024_mini.csv\")\ndf.sample(8)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:42.055406Z","iopub.execute_input":"2024-11-18T09:42:42.055699Z","iopub.status.idle":"2024-11-18T09:42:42.091983Z","shell.execute_reply.started":"2024-11-18T09:42:42.055661Z","shell.execute_reply":"2024-11-18T09:42:42.091106Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                              Question  \\\n460  What did the Speaker emphasize about discussio...   \n73   How does the government plan to support domest...   \n231  Who conveyed congratulations on behalf of the ...   \n175  Who is the member from Arani and in which lang...   \n237  Who expressed concerns about passing Bills wit...   \n425  What was Shri Rahul Gandhi  request related to...   \n155  Who represents Thane and took the oath in Mara...   \n55   How has the National Education Policy 2020 cha...   \n\n                                               Context  \\\n460  The Speaker highlighted the need for discussio...   \n73   The government plans to develop infrastructure...   \n231  Adv. Francis George from the Kerala Congress P...   \n175  Shri Tharaniventhan M.S. from Arani took the a...   \n237  Adv. Francis George from Kerala Congress expre...   \n425  Shri Rahul Gandhi wanted to address student is...   \n155  Shri Naresh Ganpat Mhaske from Thane took the ...   \n55   The National Education Policy 2020 introduces ...   \n\n                                                Answer  \n460  The Speaker emphasized that discussions should...  \n73   To support domestic tourism growth, the govern...  \n231  Adv. Francis George congratulated Shri Om Birl...  \n175  Shri Tharaniventhan M.S. represents Arani and ...  \n237  Adv. Francis George voiced concerns about Bill...  \n425  He requested a discussion focused on student i...  \n155  Shri Naresh Ganpat Mhaske represents Thane and...  \n55   The National Education Policy 2020 has brought...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Context</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>460</th>\n      <td>What did the Speaker emphasize about discussio...</td>\n      <td>The Speaker highlighted the need for discussio...</td>\n      <td>The Speaker emphasized that discussions should...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>How does the government plan to support domest...</td>\n      <td>The government plans to develop infrastructure...</td>\n      <td>To support domestic tourism growth, the govern...</td>\n    </tr>\n    <tr>\n      <th>231</th>\n      <td>Who conveyed congratulations on behalf of the ...</td>\n      <td>Adv. Francis George from the Kerala Congress P...</td>\n      <td>Adv. Francis George congratulated Shri Om Birl...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>Who is the member from Arani and in which lang...</td>\n      <td>Shri Tharaniventhan M.S. from Arani took the a...</td>\n      <td>Shri Tharaniventhan M.S. represents Arani and ...</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>Who expressed concerns about passing Bills wit...</td>\n      <td>Adv. Francis George from Kerala Congress expre...</td>\n      <td>Adv. Francis George voiced concerns about Bill...</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>What was Shri Rahul Gandhi  request related to...</td>\n      <td>Shri Rahul Gandhi wanted to address student is...</td>\n      <td>He requested a discussion focused on student i...</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>Who represents Thane and took the oath in Mara...</td>\n      <td>Shri Naresh Ganpat Mhaske from Thane took the ...</td>\n      <td>Shri Naresh Ganpat Mhaske represents Thane and...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>How has the National Education Policy 2020 cha...</td>\n      <td>The National Education Policy 2020 introduces ...</td>\n      <td>The National Education Policy 2020 has brought...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"For easiness, we will create the following template for QA: ","metadata":{}},{"cell_type":"code","source":"template = \"\\n\\nQuestion:\\n{Question}\\n\\nAnswer:\\n{Answer}\"\n\ndf[\"prompt\"] = df.apply(lambda row: template.format(Question=row.Question,\n                                                    Answer=row.Answer), axis=1)\ndata = df.prompt.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:42.093181Z","iopub.execute_input":"2024-11-18T09:42:42.093780Z","iopub.status.idle":"2024-11-18T09:42:42.112903Z","shell.execute_reply.started":"2024-11-18T09:42:42.093737Z","shell.execute_reply":"2024-11-18T09:42:42.111997Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Template utility function","metadata":{}},{"cell_type":"code","source":"def colorize_text(text):\n    for word, color in zip([\"Question\", \"Answer\"], [\"red\", \"green\"]):\n        text = text.replace(f\"\\n\\n{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:42.113836Z","iopub.execute_input":"2024-11-18T09:42:42.114104Z","iopub.status.idle":"2024-11-18T09:42:42.122205Z","shell.execute_reply.started":"2024-11-18T09:42:42.114074Z","shell.execute_reply":"2024-11-18T09:42:42.121400Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Specialized class to query Gemma\n\n\nWe define a specialized class to query Gemma. But first, we need to initialize an object of GemmaCausalLM class.","metadata":{}},{"cell_type":"markdown","source":"## Initialize the code for Gemma Causal LM","metadata":{}},{"cell_type":"code","source":"import keras_nlp\nprint(keras_nlp.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:53.717255Z","iopub.execute_input":"2024-11-18T09:42:53.717601Z","iopub.status.idle":"2024-11-18T09:42:53.723006Z","shell.execute_reply.started":"2024-11-18T09:42:53.717558Z","shell.execute_reply":"2024-11-18T09:42:53.722022Z"},"trusted":true},"outputs":[{"name":"stdout","text":"0.17.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"gemma_causal_lm = keras_nlp.models.GemmaCausalLM.from_preset(Config.preset)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:42:53.727923Z","iopub.execute_input":"2024-11-18T09:42:53.728351Z","iopub.status.idle":"2024-11-18T09:43:47.300135Z","shell.execute_reply.started":"2024-11-18T09:42:53.728293Z","shell.execute_reply":"2024-11-18T09:43:47.299193Z"},"trusted":true},"outputs":[{"name":"stderr","text":"normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"gemma_causal_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:43:47.301237Z","iopub.execute_input":"2024-11-18T09:43:47.301539Z","iopub.status.idle":"2024-11-18T09:43:47.333432Z","shell.execute_reply.started":"2024-11-18T09:43:47.301507Z","shell.execute_reply":"2024-11-18T09:43:47.332544Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Define the specialized class\n\nHere we define the special class `GemmaQA`. \nin the `__init__` we pass the `GemmaCausalLM` object created before.\nThe `query` member function uses `GemmaCausalLM` member function `generate` to generate the answer, based on a prompt that includes the category and the question.","metadata":{}},{"cell_type":"code","source":"class GemmaQA:\n    def __init__(self, max_length=512):\n        self.max_length = max_length\n        self.prompt = template\n        self.gemma_causal_lm = gemma_causal_lm\n        \n    def query(self, question):\n        response = self.gemma_causal_lm.generate(\n            self.prompt.format(\n                Question=question,\n                Answer=\"\"), \n            max_length=self.max_length)\n        display(Markdown(colorize_text(response)))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:43:47.334595Z","iopub.execute_input":"2024-11-18T09:43:47.334892Z","iopub.status.idle":"2024-11-18T09:43:47.340245Z","shell.execute_reply.started":"2024-11-18T09:43:47.334859Z","shell.execute_reply":"2024-11-18T09:43:47.339342Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Gemma preprocessor\n\n\nThis preprocessing layer will take in batches of strings, and return outputs in a ```(x, y, sample_weight)``` format, where the y label is the next token id in the x sequence.\n\nFrom the code below, we can see that, after the preprocessor, the data shape is ```(num_samples, sequence_length)```.","metadata":{}},{"cell_type":"code","source":"x, y, sample_weight = gemma_causal_lm.preprocessor(data[0:2])","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:43:47.341437Z","iopub.execute_input":"2024-11-18T09:43:47.341798Z","iopub.status.idle":"2024-11-18T09:43:47.442733Z","shell.execute_reply.started":"2024-11-18T09:43:47.341756Z","shell.execute_reply":"2024-11-18T09:43:47.441825Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Perform fine-tuning with LoRA","metadata":{}},{"cell_type":"markdown","source":"## Enable LoRA for the model\n\nLoRA rank is setting the number of trainable parameters. A larger rank will result in a larger number of parameters to train.","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to the lora_rank as set in Config (4).\ngemma_causal_lm.backbone.enable_lora(rank=Config.lora_rank)\ngemma_causal_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:43:47.443988Z","iopub.execute_input":"2024-11-18T09:43:47.444296Z","iopub.status.idle":"2024-11-18T09:43:47.737386Z","shell.execute_reply.started":"2024-11-18T09:43:47.444265Z","shell.execute_reply":"2024-11-18T09:43:47.736497Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Run the training sequence\n\nWe set the `sequence_length` for the `GemmaCausalLM` (from configuration, will be 512).\nWe compile the model, with the loss, optimizer and metric.\nFor the metric, it is used `SparseCategoricalAccuracy`. This metric calculates how often predictions match integer labels.","metadata":{}},{"cell_type":"code","source":"#set sequence length cf. config (512)\ngemma_causal_lm.preprocessor.sequence_length = Config.sequence_length \n\n# Compile the model with loss, optimizer, and metric\ngemma_causal_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Train model\ngemma_causal_lm.fit(data, epochs=Config.epochs, batch_size=Config.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:43:47.738521Z","iopub.execute_input":"2024-11-18T09:43:47.738815Z","iopub.status.idle":"2024-11-18T11:06:47.008453Z","shell.execute_reply.started":"2024-11-18T09:43:47.738783Z","shell.execute_reply":"2024-11-18T11:06:47.007559Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 855ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.6039\nEpoch 2/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 819ms/step - loss: 0.1353 - sparse_categorical_accuracy: 0.6834\nEpoch 3/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.7014\nEpoch 4/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.1145 - sparse_categorical_accuracy: 0.7190\nEpoch 5/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.7405\nEpoch 6/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.7658\nEpoch 7/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.7891\nEpoch 8/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.8160\nEpoch 9/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.8434\nEpoch 10/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 820ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.8646\nEpoch 11/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 819ms/step - loss: 0.0418 - sparse_categorical_accuracy: 0.8869\nEpoch 12/12\n\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 819ms/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9003\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f90fc538550>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Test the fine-tuned model\n\nWe instantiate an object of class GemmaQA. Because `gemma_causal_lm` was fine-tuned using LoRA, `gemma_qa` defined here will use the fine-tuned model.","metadata":{}},{"cell_type":"code","source":"gemma_qa = GemmaQA()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:06:47.009836Z","iopub.execute_input":"2024-11-18T11:06:47.010535Z","iopub.status.idle":"2024-11-18T11:06:47.015064Z","shell.execute_reply.started":"2024-11-18T11:06:47.010486Z","shell.execute_reply":"2024-11-18T11:06:47.014100Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"For start, we will testing the model with some of the data from the training set itself.","metadata":{}},{"cell_type":"code","source":"row = df.iloc[0]\ngemma_qa.query(row.Question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:06:47.016489Z","iopub.execute_input":"2024-11-18T11:06:47.016776Z","iopub.status.idle":"2024-11-18T11:07:03.617628Z","shell.execute_reply.started":"2024-11-18T11:06:47.016746Z","shell.execute_reply":"2024-11-18T11:07:03.616687Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat is the goal of the 'Sabka Saath, Sabka Vikas' philosophy?\n\n**<font color='green'>Answer:</font>**\n'Sabka Saath, Sabka Vikas' is a philosophy that emphasizes inclusive growth, intending to reach every social and geographical section in India, and foster equal opportunities and prosperity for all segments of society."},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"row = df.iloc[3]\ngemma_qa.query(row.Question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:07:03.618883Z","iopub.execute_input":"2024-11-18T11:07:03.619255Z","iopub.status.idle":"2024-11-18T11:07:05.270910Z","shell.execute_reply.started":"2024-11-18T11:07:03.619220Z","shell.execute_reply":"2024-11-18T11:07:05.269961Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat is the PM-KISAN SAMMAN Yojana, and who benefits from it?\n\n**<font color='green'>Answer:</font>**\nPM-KISAN SAMMAN Yojana is a program that provides direct financial assistance to 11.8 crore farmers, focusing on supporting small and marginal farmers."},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"row = df.iloc[105]\ngemma_qa.query(row.Question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:07:05.272167Z","iopub.execute_input":"2024-11-18T11:07:05.272830Z","iopub.status.idle":"2024-11-18T11:07:06.249865Z","shell.execute_reply.started":"2024-11-18T11:07:05.272784Z","shell.execute_reply":"2024-11-18T11:07:06.248914Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWho took the oath in Manipuri on June 25, 2024?\n\n**<font color='green'>Answer:</font>**\nShri Angomcha Bimol Akoijam took the oath in Manipuri."},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Test the model with unseen question(s)","metadata":{}},{"cell_type":"code","source":"question = \"How is the government promoting inclusive education for the disabled?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:15:48.594524Z","iopub.execute_input":"2024-11-18T11:15:48.595275Z","iopub.status.idle":"2024-11-18T11:15:49.613366Z","shell.execute_reply.started":"2024-11-18T11:15:48.595237Z","shell.execute_reply":"2024-11-18T11:15:49.612418Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nHow is the government promoting inclusive education for the disabled?\n\n**<font color='green'>Answer:</font>**\nInclusive education promotes equal access for disabled students, with focus on modern facilities and resources."},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"question = \"How has India promoted renewable energy?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:17:33.134871Z","iopub.execute_input":"2024-11-18T12:17:33.135521Z","iopub.status.idle":"2024-11-18T12:17:34.759590Z","shell.execute_reply.started":"2024-11-18T12:17:33.135479Z","shell.execute_reply":"2024-11-18T12:17:34.758601Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nHow has India promoted renewable energy?\n\n**<font color='green'>Answer:</font>**\nIndia promotes renewable energy, aiming for 5 gigawatts of wind energy and 10 gigawatts of solar energy by 2027."},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"question = \"What disaster relief funds are available to Tamil Nadu?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:17:40.399784Z","iopub.execute_input":"2024-11-18T12:17:40.400170Z","iopub.status.idle":"2024-11-18T12:17:41.595095Z","shell.execute_reply.started":"2024-11-18T12:17:40.400115Z","shell.execute_reply":"2024-11-18T12:17:41.594203Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat disaster relief funds are available to Tamil Nadu?\n\n**<font color='green'>Answer:</font>**\nThe government has released Rs. 1,111 crore from the NDRF for Tamil Nadu."},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"question = \"What is the current disaster relief fund status for Tamil Nadu?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T12:17:47.101080Z","iopub.execute_input":"2024-11-18T12:17:47.101454Z","iopub.status.idle":"2024-11-18T12:17:48.080271Z","shell.execute_reply.started":"2024-11-18T12:17:47.101421Z","shell.execute_reply":"2024-11-18T12:17:48.079367Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat is the current disaster relief fund status for Tamil Nadu?\n\n**<font color='green'>Answer:</font>**\nThe government has released partial aid for Tamil Nadu's relief and restoration efforts."},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"question = \"Who congratulated Shri Om Birla on behalf of the INDIA Alliance?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:26:46.817840Z","iopub.execute_input":"2024-11-18T11:26:46.818705Z","iopub.status.idle":"2024-11-18T11:26:48.175690Z","shell.execute_reply.started":"2024-11-18T11:26:46.818664Z","shell.execute_reply":"2024-11-18T11:26:48.174767Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWho congratulated Shri Om Birla on behalf of the INDIA Alliance?\n\n**<font color='green'>Answer:</font>**\nShri Rahul Gandhi congratulated Shri Om Birla on behalf of the INDIA Alliance, highlighting the importance of a non-partisan approach."},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"question = \"What is the focus of India  National Solar Mission?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:15:26.186658Z","iopub.execute_input":"2024-11-18T11:15:26.187073Z","iopub.status.idle":"2024-11-18T11:15:27.101902Z","shell.execute_reply.started":"2024-11-18T11:15:26.187026Z","shell.execute_reply":"2024-11-18T11:15:27.100904Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nWhat is the focus of India  National Solar Mission?\n\n**<font color='green'>Answer:</font>**\nIndia  National Solar Mission aims to expand solar energy adoption across sectors."},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"question = \"How is the Ministry of Health addressing the shortage of healthcare professionals?\"\ngemma_qa.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:15:17.283268Z","iopub.execute_input":"2024-11-18T11:15:17.283991Z","iopub.status.idle":"2024-11-18T11:15:18.313892Z","shell.execute_reply.started":"2024-11-18T11:15:17.283949Z","shell.execute_reply":"2024-11-18T11:15:18.312935Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"\n\n**<font color='red'>Question:</font>**\nHow is the Ministry of Health addressing the shortage of healthcare professionals?\n\n**<font color='green'>Answer:</font>**\nThe Ministry is addressing the shortage by increasing medical and para-medical education seats."},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"preset_dir = \".\\gemma2_2b_en_policylens_model\"\ngemma_causal_lm.save_to_preset(preset_dir)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T11:07:15.451907Z","iopub.execute_input":"2024-11-18T11:07:15.452254Z","iopub.status.idle":"2024-11-18T11:07:57.514292Z","shell.execute_reply.started":"2024-11-18T11:07:15.452215Z","shell.execute_reply":"2024-11-18T11:07:57.513187Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Conclusions\n\n","metadata":{}},{"cell_type":"markdown","source":"> - Fine-tuning of a **Gemma 2** model has been demonstated using LoRA.   \n> -  A class was alos created to run queries to the **Gemma 2** model and tested it with some examples from the existing training data but also with some new, unseen questions.   \n> - The models was as a Keras model.\n> - The model was evaluated using Perplexity,recorded Perplexity value of 2.502. \n> - Finnally, the model was published as a Kaggle Model on Kaggle Models platform.","metadata":{}}]}